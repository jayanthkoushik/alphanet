<!-- cSpell:ignore Torralba, Alshammari, Mensink, Changpinyo, Aytar -->

# Related work {#sec:relwork}

Our work falls in the domain of long-tail learning, where the
distribution of class sizes -- measured via number of training samples
-- models that of the visual world; many classes have only a few
samples, while a small number have many[@2023.Feng.Zhang]. Kang
et\ al.[@2020.Kalantidis.Kang] established strong baselines on
long-tailed datasets by decoupling classifiers and representations. We
apply AlphaNet to of their proposed baseline methods: (1) the cRT
(classifier re-training) model, which fixes representations, and trains
classifiers from scratch; and (2) the LWS (learnable weight scaling)
model, which also fixes representations, and only _rescales_
classifiers, with scales learned from the training data.

In contrast to the above simple methods, many complex methods have been
proposed, and have continued to push the state-of-the-art for long-tail
recognition[@2019.Yu.Liu; @2021.Yu.Wang; @2021.Wu.Li; @2021.Hwang.Cai;
@2022.Kong.Alshammari]. We used two of these methods to evaluate
AlphaNet: (1) the RIDE (RoutIng Diverse Experts) model of Wang
et\ al.[@2021.Yu.Wang], which achieves low bias and variance, by
training with a "distribution-aware diversity loss" and using multiple
experts, respectively; and (2) the LTR (long-tail recognition) model of
Alshammari et\ al.[@2022.Kong.Alshammari], which uses a combination of
class-balanced loss, weight decay, and max-norm regularization -- in
this work we will refer to this model simply as the LTR model.

In the rest of this section, we discuss some works that make use of
similar ideas as AlphaNet.

## Knowledge transfer {#sec:relwork:transfer}

AlphaNet bears resemblance to methods that create new classifiers by
transferring knowledge from existing classifiers. These methods appear
in a number of domains, such as transfer learning, meta-learning, and
multi-task learning[@2012.Lorien.Thrun; @1997.Caruana;
@1997.Wiering.Schmidhuber; @2010.Yang.Pan]. It should be noted, however,
that AlphaNet does not create new classifiers -- it only _modifies_
existing classifiers by combining them with others.

Pertinent to our problem setting is the work by Wang
et\ al.[@2016.Hebert.Wang], who showed that a "generic, category agnostic
transformation" can be learned from models trained on few samples, to
models trained on many samples. In our work, we implicitly learn a
similar transformation, but with the source and target classifiers
within the same model. Additionally, the transformation is constrained
to be a linear combination. A similar paradigm was analyzed by Du
et\ al.[@2016.Poczos.Du], who showed that for cases where the target
function is generated by a simple transformation of the source function,
there are theoretical performance guarantees for a large class of
functions.

## Classifier composition {#sec:relwork:composition}

In low-shot[^note:low_shot] and zero-shot classification, new
classifiers are learned using few or zero training
examples[@2006.Perona.Fei-Fei; @2008.Bengio.Larochelle]. Some methods
have done this by directly combining existing classifiers. For example,
Mensink et\ al.[@2014.Snoek.Mensink] learned new classifiers as linear
combinations of existing classifiers, with weights determined by
co-occurrence statistics. Changpinyo et\ al.[@2016.Sha.Changpinyo]
introduced "phantom classes" and used their classifiers as bases to
compose new classifiers through convex combination.

The idea of combining existing classifiers was also used by Aytar
et\ al.[@2015.Zisserman.Aytar], in their work on enhancing single
exemplar support vector machines (SVMs). In their method, an extra
regularization term is added to the SVM loss function, which encourages
the learned classifier to be close to a linear combination of previously
learned classifiers. Classifiers trained on image patches are used to
transfer knowledge to a classifier trained on a single positive
exemplar.

### Boosting {#sec:relwork:composition:boosting}

Composing weak classifiers to build strong classifiers also bears
resemblance to the idea of boosting[@1990.Schapire]. The popular
AdaBoost[@1997.Schapire.Freund] algorithm linearly combines classifiers
based on single features (e.g., decision stumps), and iteratively
re-weights training samples based on their error. For the case of
multi-class classification, Torralba et\ al.[@2007.Freeman.Torralba]
built a classifier that combines several binary classifiers, each
designed to separate a single class from the others. Their method
identifies common features that be shared across classifiers, which
reduces the computational load, and the amount of training data
required.

It is important to note that boosting methods employ a different form of
composition that our methods. Specifically, our focus is on
classification methods where the performance on a _subset of classes_ is
poor. Unlike boosting methods, we do not incorporate additional features
-- improvements are made by adjusting classifiers within the learned
representation space.

[^note:low_shot]: Low-shot learning is also referred to as few-shot
    learning, and as one-shot learning if only a single training example
    is available per class.
