@article{2012.Crair.Ackman,
year = {2012},
title = {Retinal waves coordinate patterned activity throughout the developing visual system},
author = {Ackman, James B and Burbridge, Timothy J and Crair, Michael C},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature11529},
pmid = {23060192},
pmcid = {PMC3962269},
pages = {219--225},
number = {7419},
volume = {490},
keywords = {},
}
@article{2012.Linke.Cusack,
year = {2011},
rating = {0},
title = {Seeing different objects in different ways: Measuring ventral visual tuning to sensory and semantic features with dynamically adaptive imaging},
author = {Cusack, Rhodri and Veldsman, Michele and Naci, Lorina and Mitchell, Daniel J. and Linke, Annika C.},
journal = {Human Brain Mapping},
issn = {1097-0193},
doi = {10.1002/hbm.21219},
pmid = {21391273},
pages = {387--397},
number = {2},
volume = {33},
language = {English},
keywords = {},
month = {03},
}
@article{2017.Boult.Günther,
year = {2017},
title = {Toward Open-Set Face Recognition},
author = {Günther, Manuel and Cruz, Steve and Rudd, Ethan M. and Boult, Terrance E.},
journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
doi = {10.1109/cvprw.2017.85},
pages = {573--582},
keywords = {},
}
@article{2021.Crair.Ge,
year = {2021},
title = {Retinal waves prime visual motion detection by simulating future optic flow},
author = {Ge, Xinxin and Zhang, Kathy and Gribizis, Alexandra and Hamodi, Ali S. and Sabino, Aude Martinez and Crair, Michael C.},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.abd0830},
pmid = {34437090},
pages = {eabd0830},
number = {6553},
volume = {373},
keywords = {},
}
@article{1974.Rakic.Rakic,
year = {1974},
title = {Neurons in Rhesus Monkey Visual Cortex: Systematic Relation between Time of Origin and Eventual Disposition},
author = {Rakic, P},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.183.4123.425},
pmid = {4203022},
pages = {425--427},
number = {4123},
volume = {183},
keywords = {},
}
@article{2021.Jia.Zhong,
year = {2021},
title = {Improving Calibration for Long-Tailed Recognition},
author = {Zhong, Zhisheng and Cui, Jiequan and Liu, Shu and Jia, Jiaya},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.01622},
pages = {16484--16493},
volume = {00},
keywords = {}
}
@article{2015.Tenenbaum.Lake,
year = {2015},
title = {Human-level concept learning through probabilistic program induction},
author = {Lake, Brenden M. and Salakhutdinov, Ruslan and Tenenbaum, Joshua B.},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.aab3050},
pmid = {26659050},
pages = {1332--1338},
number = {6266},
volume = {350},
}
@article{2014.Proutiere.Magureanu,
year = {2014},
rating = {0},
title = {Lipschitz Bandits: Regret Lower Bounds and Optimal Algorithms},
author = {Magureanu, Stefan and Combes, Richard and Proutiere, Alexandre},
journal = {arXiv},
eprint = {1405.4758},
url = {arXiv.org},
volume = {cs.LG},
note = {COLT 2014},
keywords = {},
month = {05},
}
@article{2019.Chellappa.Dhar,
year = {2019},
title = {Learning without Memorizing},
author = {Dhar, Prithviraj and Singh, Rajat Vikram and Peng, Kuan-Chuan and Wu, Ziyan and Chellappa, Rama},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.00528},
pages = {5133--5141},
volume = {00},
keywords = {},
}
@article{2020.Yu.Wang,
year = {2020},
title = {Long-tailed Recognition by Routing Diverse Distribution-Aware Experts},
author = {Wang, Xudong and Lian, Long and Miao, Zhongqi and Liu, Ziwei and Yu, Stella X},
journal = {arXiv},
doi = {10.48550/arxiv.2010.01809},
eprint = {2010.01809},
abstract = {Natural data are often long-tail distributed over semantic classes. Existing recognition methods tackle this imbalanced classification by placing more emphasis on the tail data, through class re-balancing/re-weighting or ensembling over different data groups, resulting in increased tail accuracies but reduced head accuracies. We take a dynamic view of the training data and provide a principled model bias and variance analysis as the training data fluctuates: Existing long-tail classifiers invariably increase the model variance and the head-tail model bias gap remains large, due to more and larger confusion with hard negatives for the tail. We propose a new long-tailed classifier called RoutIng Diverse Experts (RIDE). It reduces the model variance with multiple experts, reduces the model bias with a distribution-aware diversity loss, reduces the computational cost with a dynamic expert routing module. RIDE outperforms the state-of-the-art by 5\% to 7\% on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks. It is also a universal framework that is applicable to various backbone networks, long-tailed algorithms, and training mechanisms for consistent performance gains. Our code is available at: https://github.com/frank-xwang/RIDE-LongTailRecognition.}
}
@article{2011.Denk.Briggman,
year = {2011},
title = {Wiring specificity in the direction-selectivity circuit of the retina},
author = {Briggman, Kevin L and Helmstaedter, Moritz and Denk, Winfried},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature09818},
pmid = {21390125},
pages = {183--188},
number = {7337},
volume = {471},
keywords = {},
}
@article{2017.Karaoguz.Gepperth,
year = {2017},
title = {Incremental Learning with Self-Organizing Maps},
author = {Gepperth, Alexander and Karaoguz, Cem},
journal = {2017 12th International Workshop on Self-Organizing Maps and Learning Vector Quantization, Clustering and Data Visualization (WSOM)},
doi = {10.1109/wsom.2017.8020021},
pages = {1--8},
keywords = {},
}
@article{2017.Zhou.Zhoufn,
year = {2017},
title = {A brief introduction to weakly supervised learning},
author = {Zhou, Zhi-Hua},
journal = {National Science Review},
issn = {2095-5138},
doi = {10.1093/nsr/nwx106},
pages = {44--53},
number = {1},
volume = {5},
keywords = {},
}
@article{1953.Barlow.Barlow,
year = {1953},
title = {Summation and inhibition in the frog's retina},
author = {Barlow, H B},
journal = {The Journal of Physiology},
issn = {0022-3751},
doi = {10.1113/jphysiol.1953.sp004829},
pmid = {13035718},
pages = {69--88},
number = {1},
volume = {119},
keywords = {},
}
@book{2006.Wasserman.Wasserman,
year = {2006},
title = {All of Nonparametric Statistics},
author = {Wasserman, Larry},
isbn = {9780387251455},
series = {Springer Texts in Statistics},
keywords = {},
doi = {10.1007/0-387-30623-4\_1},
}
@article{2008.Dan.Caporale,
year = {2008},
title = {Spike timing-dependent plasticity: a Hebbian learning rule.},
author = {Caporale, Natalia and Dan, Yang},
journal = {Annual review of neuroscience},
issn = {0147-006X},
doi = {10.1146/annurev.neuro.31.060407.125639},
pmid = {18275283},
pages = {25--46},
number = {1},
volume = {31},
keywords = {},
}
@article{2006.Perona.Fei-Fei,
year = {2006},
title = {One-Shot Learning of Object Categories},
author = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2006.79},
pmid = {16566508},
pages = {594--611},
number = {4},
volume = {28},
}
@article{2005.Dan.Felsen,
year = {2005},
title = {A natural approach to studying vision},
author = {Felsen, Gidon and Dan, Yang},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/nn1608},
pmid = {16306891},
pages = {1643--1646},
number = {12},
volume = {8},
keywords = {},
}
@article{2020.Mao.Maov5m,
year = {2020},
title = {A Survey on Self-supervised Pre-training for Sequential Transfer Learning in Neural Networks},
author = {Mao, Huanru Henry},
journal = {arXiv},
eprint = {2007.00800},
keywords = {}
}
@article{2014.Vaart.Vaart,
year = {2014},
rating = {0},
title = {Higher Order Tangent Spaces and Influence Functions},
author = {Vaart, Aad van der},
journal = {Statistical Science},
issn = {0883-4237},
doi = {10.1214/14-sts478},
eprint = {1502.00812},
pages = {679--686},
number = {4},
volume = {29},
keywords = {},
}
@article{2019.Yu.Liu,
year = {2019},
title = {Large-Scale Long-Tailed Recognition in an Open World},
author = {Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X.},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.00264},
pages = {2532--2541},
volume = {00},
keywords = {},
}
@article{2018.Popescu.Belouadah,
year = {2018},
title = {DeeSIL: Deep-Shallow Incremental Learning},
author = {Belouadah, Eden and Popescu, Adrian},
journal = {arXiv},
eprint = {1808.06396},
keywords = {},
}
@article{2002.Alonso.Egorov,
year = {2002},
title = {Graded persistent activity in entorhinal cortex neurons},
author = {Egorov, Alexei V. and Hamam, Bassam N. and Fransén, Erik and Hasselmo, Michael E. and Alonso, Angel A.},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature01171},
pmid = {12432392},
pages = {173--178},
number = {6912},
volume = {420},
keywords = {},
}
@inproceedings{Salakhutdinov.Koch,
author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
title = {Siamese neural networks for one-shot image recognition},
booktitle = {ICML deep learning workshop},
pages = {0},
volume = {2},
}
@article{2014.Li.Dudík,
year = {2014-11},
rating = {0},
title = {Doubly Robust Policy Evaluation and Optimization},
author = {Dudík, Miroslav and Erhan, Dumitru and Langford, John and Li, Lihong},
journal = {Statistical Science},
issn = {0883-4237},
doi = {10.1214/14-sts500},
eprint = {1503.02834},
pages = {485--511},
number = {4},
volume = {29},
language = {English},
keywords = {},
}
@article{2017.Hoiem.Li,
year = {2017},
title = {Learning without Forgetting},
author = {Li, Zhizhong and Hoiem, Derek},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2017.2773081},
pmid = {29990101},
pages = {2935--2947},
number = {12},
volume = {40},
}
@article{2016.Lillicrap.Santoro,
year = {2016},
title = {One-shot Learning with Memory-Augmented Neural Networks},
author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
journal = {arXiv},
doi = {10.48550/arxiv.1605.06065},
eprint = {1605.06065},
abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.}
}
@article{2017.Hutter.Loshchilov,
year = {2017},
title = {Decoupled Weight Decay Regularization},
author = {Loshchilov, Ilya and Hutter, Frank},
journal = {arXiv},
doi = {10.48550/arxiv.1711.05101},
eprint = {1711.05101},
abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslashemph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslashemph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW}
}
@article{2019.Ma.Cao,
year = {2019},
title = {Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss},
author = {Cao, Kaidi and Wei, Colin and Gaidon, Adrien and Arechiga, Nikos and Ma, Tengyu},
journal = {arXiv},
doi = {10.48550/arxiv.1906.07413},
eprint = {1906.07413},
abstract = {Deep learning algorithms can fare poorly when the training dataset suffers from heavy class-imbalance but the testing criterion requires good generalization on less frequent classes. We design two novel methods to improve performance in such scenarios. First, we propose a theoretically-principled label-distribution-aware margin (LDAM) loss motivated by minimizing a margin-based generalization bound. This loss replaces the standard cross-entropy objective during training and can be applied with prior strategies for training with class-imbalance such as re-weighting or re-sampling. Second, we propose a simple, yet effective, training schedule that defers re-weighting until after the initial stage, allowing the model to learn an initial representation while avoiding some of the complications associated with re-weighting or re-sampling. We test our methods on several benchmark vision tasks including the real-world imbalanced dataset iNaturalist 2018. Our experiments show that either of these methods alone can already improve over existing techniques and their combination achieves even better performance gains.}
}
@article{2019.Tuytelaars.Aljundi,
year = {2019},
title = {Task-Free Continual Learning},
author = {Aljundi, Rahaf and Kelchtermans, Klaas and Tuytelaars, Tinne},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.01151},
pages = {11246--11255},
volume = {00},
keywords = {},
}
@article{2021.Yang.Wei,
year = {2021},
title = {CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning},
author = {Wei, Chen and Sohn, Kihyuk and Mellina, Clayton and Yuille, Alan and Yang, Fan},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.01071},
pages = {10852--10861},
volume = {00},
keywords = {}
}
@article{2021.Wang.Wang,
year = {2021},
title = {Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification},
author = {Wang, Peng and Han, Kai and Wei, Xiu-Shen and Zhang, Lei and Wang, Lei},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00100},
pages = {943--952},
volume = {00},
keywords = {}
}
@article{2020.Hinton.Chen,
year = {2020},
title = {A Simple Framework for Contrastive Learning of Visual Representations},
author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
journal = {arXiv},
eprint = {2002.05709},
keywords = {},
}
@article{1991.Shatz.Meister,
year = {1991},
title = {Synchronous bursts of action potentials in ganglion cells of the developing mammalian retina},
author = {Meister, M and Wong, R and Baylor, D and Shatz, C},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.2035024},
pmid = {2035024},
pages = {939--943},
number = {5008},
volume = {252},
keywords = {}
}
@article{2020.Kanellos.Belouadah,
year = {2020},
title = {A Comprehensive Study of Class Incremental Learning Algorithms for Visual Tasks},
author = {Belouadah, Eden and Popescu, Adrian and Kanellos, Ioannis},
journal = {arXiv},
eprint = {2011.01844},
keywords = {},
}
@article{2017.Kalita.Doan,
year = {2017},
title = {Overcoming the Challenge for Text Classification in the Open World},
author = {Doan, Tri and Kalita, Jugal},
journal = {2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC)},
doi = {10.1109/ccwc.2017.7868366},
pages = {1--7},
keywords = {}
}
@article{2016.Freitas.Andrychowicz,
year = {2016},
title = {Learning to learn by gradient descent by gradient descent},
author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and Freitas, Nando de},
journal = {arXiv},
doi = {10.48550/arxiv.1606.04474},
eprint = {1606.04474},
abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.}
}
@article{1991.Grinvald.Bonhoeffer,
year = {1991},
title = {Iso-orientation domains in cat visual cortex are arranged in pinwheel-like patterns},
author = {Bonhoeffer, Tobias and Grinvald, Amiram},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/353429a0},
pmid = {1896085},
pages = {429--431},
number = {6343},
volume = {353},
keywords = {},
}
@article{2015.Schmid.Akata,
year = {2015},
title = {Label-Embedding for Image Classification},
author = {Akata, Zeynep and Perronnin, Florent and Harchaoui, Zaid and Schmid, Cordelia},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2015.2487986},
pmid = {26452251},
eprint = {1503.08677},
pages = {1425--1438},
number = {7},
volume = {38},
}
@article{2017.Kira.Hsu,
year = {2017},
title = {Learning to cluster in order to transfer across domains and tasks},
author = {Hsu, Yen-Chang and Lv, Zhaoyang and Kira, Zsolt},
journal = {arXiv},
eprint = {1711.10125},
keywords = {},
}
@article{2020.Gong.Tao,
year = {2020},
title = {Computer Vision – ECCV 2020, 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIX},
author = {Tao, Xiaoyu and Chang, Xinyuan and Hong, Xiaopeng and Wei, Xing and Gong, Yihong},
journal = {Lecture Notes in Computer Science},
issn = {0302-9743},
doi = {10.1007/978-3-030-58529-7\_16},
pages = {254--270},
keywords = {},
}
@article{2005.Movshon.Rust,
year = {2005},
title = {In praise of artifice},
author = {Rust, Nicole C and Movshon, J Anthony},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/nn1606},
pmid = {16306892},
pages = {1647--1650},
number = {12},
volume = {8},
keywords = {},
}
@article{2014.Alfons.Öllerer,
year = {2015},
rating = {0},
title = {The influence function of penalized regression estimators},
author = {Öllerer, Viktoria and Croux, Christophe and Alfons, Andreas},
journal = {Statistics},
issn = {0233-1888},
doi = {10.1080/02331888.2014.922563},
eprint = {1501.01208},
url = {arXiv.org},
pages = {741--765},
number = {4},
volume = {49},
language = {English},
note = {appears in Statistics: A Journal of Theoretical and Applied Statistics, 2014},
keywords = {},
month = {01},
}
@article{2021.Baraniuk.Balestriero,
year = {2021},
title = {Mad Max: Affine Spline Insights Into Deep Learning},
author = {Balestriero, Randall and Baraniuk, Richard G.},
journal = {Proceedings of the IEEE},
issn = {0018-9219},
doi = {10.1109/jproc.2020.3042100},
pages = {704--727},
number = {5},
volume = {109},
keywords = {},
}
@article{2006.Chalupa.Warland,
year = {2006},
rating = {0},
title = {Dynamics of Spontaneous Activity in the Fetal Macaque Retina during Development of Retinogeniculate Pathways},
author = {Warland, David K. and Huberman, Andrew D. and Chalupa, Leo M.},
journal = {Journal of Neuroscience},
issn = {0270-6474},
doi = {10.1523/jneurosci.0328-06.2006},
pmid = {16687510},
pages = {5190--5197},
number = {19},
volume = {26},
language = {English},
keywords = {},
month = {05},
}
@article{2016.Pelayo.Martínez-Cañada,
year = {2016},
rating = {0},
title = {A Computational Framework for Realistic Retina Modeling},
author = {Martínez-Cañada, Pablo and Morillas, Christian and Pino, Begoña and Ros, Eduardo and Pelayo, Francisco},
journal = {International Journal of Neural Systems},
issn = {0129-0657},
doi = {10.1142/s0129065716500301},
pmid = {27354192},
pages = {1650030},
number = {07},
volume = {26},
language = {English},
keywords = {},
}
@article{2020.Eisthen.Cesario,
year = {2020},
title = {Your Brain Is Not an Onion With a Tiny Reptile Inside},
author = {Cesario, Joseph and Johnson, David J and Eisthen, Heather L},
journal = {Current Directions in Psychological Science},
issn = {0963-7214},
doi = {10.1177/0963721420917687},
pages = {096372142091768},
number = {3},
volume = {29},
keywords = {},
}
@article{1997.Wiering.Schmidhuber,
year = {1997},
title = {Shifting Inductive Bias with Success-Story Algorithm, Adaptive Levin Search, and Incremental Self-Improvement},
author = {Schmidhuber, Jürgen and Zhao, Jieyu and Wiering, Marco},
journal = {Machine Learning},
issn = {0885-6125},
doi = {10.1023/a:1007383707642},
pages = {105--130},
number = {1},
volume = {28}
}
@article{2000.Nelson.Abbott,
year = {2000},
title = {Synaptic plasticity: taming the beast},
author = {Abbott, L F and Nelson, Sacha B},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/81453},
pmid = {11127835},
pages = {1178--1183},
number = {S11},
volume = {3},
keywords = {},
}
@article{Newey.Ichimura,
title = {The influence function of semiparametric estimators},
author = {Ichimura, Hidehiko and Newey, Whitney K},
doi = {10.1920/wp.cem.2015.4415},
keywords = {},
}
@article{2016.Boult.Bendale,
year = {2016},
title = {Towards Open Set Deep Networks},
author = {Bendale, Abhijit and Boult, Terrance E.},
journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2016.173},
pages = {1563--1572},
keywords = {}
}
@article{2003.Nawrot.Nawrot,
year = {2003-08},
rating = {0},
title = {Disorders of motion and depth},
author = {Nawrot, Mark},
journal = {Neurologic Clinics},
issn = {0733-8619},
doi = {10.1016/s0733-8619(02)00126-3},
pmid = {13677815},
pages = {609--629},
number = {3},
volume = {21},
language = {English},
keywords = {},
}
@article{1980.Weisberg.Cook,
year = {1980-11},
rating = {0},
title = {Characterizations of an Empirical Influence Function for Detecting Influential Cases in Regression},
author = {Cook, R Dennis and Weisberg, Sanford},
journal = {Technometrics},
issn = {0040-1706},
doi = {10.1080/00401706.1980.10486199},
pages = {495--508},
number = {4},
volume = {22},
language = {English},
keywords = {},
}
@article{2009.Hinton.Krizhevsky,
year = {2009},
title = {Learning multiple layers of features from tiny images},
author = {Krizhevsky, Alex and Hinton, Geoffrey},
}
@article{2010.Usunier.Weston,
year = {2010},
title = {Large scale image annotation: learning to rank with joint word-image embeddings},
author = {Weston, Jason and Bengio, Samy and Usunier, Nicolas},
journal = {Machine Learning},
issn = {0885-6125},
doi = {10.1007/s10994-010-5198-3},
pages = {21--35},
number = {1},
volume = {81}
}
@article{2009.Yang.Pandzsm,
year = {2009},
title = {A Survey on Transfer Learning},
author = {Pan, Sinno Jialin and Yang, Qiang},
journal = {IEEE Transactions on Knowledge and Data Engineering},
issn = {1041-4347},
doi = {10.1109/tkde.2009.191},
pages = {1345--1359},
number = {10},
volume = {22}
}
@article{2018.Boult.Dhamija,
year = {2018},
title = {Reducing Network Agnostophobia},
author = {Dhamija, Akshay Raj and Günther, Manuel and Boult, Terrance E},
journal = {arXiv},
eprint = {1811.04110},
keywords = {},
}
@article{2016.Vedaldi.Bertinetto,
year = {2016},
title = {Learning feed-forward one-shot learners},
author = {Bertinetto, Luca and Henriques, João F and Valmadre, Jack and Torr, Philip H S and Vedaldi, Andrea},
journal = {arXiv},
doi = {10.48550/arxiv.1606.05233},
eprint = {1606.05233},
abstract = {One-shot learning is usually tackled by using generative models or discriminative embeddings. Discriminative methods based on deep learning, which are very effective in other learning scenarios, are ill-suited for one-shot learning as they need large amounts of training data. In this paper, we propose a method to learn the parameters of a deep model in one shot. We construct the learner as a second deep network, called a learnet, which predicts the parameters of a pupil network from a single exemplar. In this manner we obtain an efficient feed-forward one-shot learner, trained end-to-end by minimizing a one-shot classification objective in a learning to learn formulation. In order to make the construction feasible, we propose a number of factorizations of the parameters of the pupil network. We demonstrate encouraging results by learning characters from single exemplars in Omniglot, and by tracking visual objects from a single initial exemplar in the Visual Object Tracking benchmark.}
}
@article{2020.Liang.Kumar,
year = {2020},
title = {Understanding Self-Training for Gradual Domain Adaptation},
author = {Kumar, Ananya and Ma, Tengyu and Liang, Percy},
journal = {arXiv},
eprint = {2002.11361},
keywords = {},
}
@article{2016.Feitas.Wang,
year = {2013},
rating = {0},
title = {Bayesian Optimization in a Billion Dimensions via Random Embeddings},
author = {Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and Feitas, Nando De},
journal = {Journal of Artificial Intelligence Research},
doi = {10.1613/jair.4806},
pages = {361--387},
volume = {55},
keywords = {},
}
@article{2016.Boult.Rudd,
year = {2016},
title = {The Extreme Value Machine},
author = {Rudd, Ethan M. and Jain, Lalit P. and Scheirer, Walter J. and Boult, Terrance E.},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2017.2707495},
pmid = {28541894},
eprint = {1506.06112},
pages = {762--768},
number = {3},
volume = {40},
keywords = {}
}
@article{2017.Phoenix.George,
year = {2017},
title = {A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs},
author = {George, Dileep and Lehrach, Wolfgang and Kansky, Ken and Lázaro-Gredilla, Miguel and Laan, Christopher and Marthi, Bhaskara and Lou, Xinghua and Meng, Zhaoshi and Liu, Yi and Wang, Huayan and Lavin, Alex and Phoenix, D. Scott},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.aag2612},
pmid = {29074582},
number = {6368},
volume = {358},
}
@article{2020.Eleftheriou.Woźniak,
year = {2020},
title = {Deep learning incorporating biologically inspired neural dynamics and in-memory computing},
author = {Woźniak, Stanisław and Pantazi, Angeliki and Bohnstingl, Thomas and Eleftheriou, Evangelos},
journal = {Nature Machine Intelligence},
doi = {10.1038/s42256-020-0187-0},
pages = {325--336},
number = {6},
volume = {2},
keywords = {},
}
@article{2010.Thorpe.Masquelier,
year = {2010},
rating = {0},
title = {Learning to recognize objects using waves of spikes and Spike Timing-Dependent Plasticity},
author = {Masquelier, Timothée and Thorpe, Simon J.},
journal = {The 2010 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/ijcnn.2010.5596934},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.719.6857\&rep=rep1\&type=pdf},
pages = {1--8},
keywords = {},
}
@article{2010.Lo.Lo,
year = {2010},
title = {Unsupervised Hebbian learning by recurrent multilayer neural networks for temporal hierarchical pattern recognition},
author = {Lo, James Ting-Ho},
journal = {2010 44th Annual Conference on Information Sciences and Systems (CISS)},
doi = {10.1109/ciss.2010.5464925},
pages = {1--6},
keywords = {},
}
@article{2019.Maaten.Wang,
year = {2019},
title = {SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning},
author = {Wang, Yan and Chao, Wei-Lun and Weinberger, Kilian Q and Maaten, Laurens van der},
journal = {arXiv},
eprint = {1911.04623},
keywords = {},
}
@article{2015.Halassa.Wimmer,
year = {2015},
title = {Thalamic control of sensory selection in divided attention},
author = {Wimmer, Ralf D and Schmitt, L Ian and Davidson, Thomas J and Nakajima, Miho and Deisseroth, Karl and Halassa, Michael M},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature15398},
pmid = {26503050},
pmcid = {PMC4626291},
pages = {705--709},
number = {7575},
volume = {526},
keywords = {},
}
@article{2018.Scanziani.Lien,
year = {2018},
title = {Cortical direction selectivity emerges at convergence of thalamic synapses},
author = {Lien, Anthony D and Scanziani, Massimo},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/s41586-018-0148-5},
pmid = {29795349},
pages = {80--86},
number = {7708},
volume = {558},
keywords = {},
}
@article{2014.Dean.Cox,
year = {2014},
title = {Neural networks and neuroscience-inspired computer vision.},
author = {Cox, David Daniel and Dean, Thomas},
journal = {Current biology : CB},
issn = {0960-9822},
doi = {10.1016/j.cub.2014.08.026},
pmid = {25247371},
pages = {R921--9},
number = {18},
volume = {24},
keywords = {},
}
@article{2019.Gerstner.Pogodin,
year = {2019},
title = {Working memory facilitates reward-modulated Hebbian learning in recurrent neural networks},
author = {Pogodin, Roman and Corneil, Dane and Seeholzer, Alexander and Heng, Joseph and Gerstner, Wulfram},
journal = {arXiv},
eprint = {1910.10559},
keywords = {}
}
@article{1966.Robson.Enroth-Cugell,
year = {1966},
title = {The contrast sensitivity of retinal ganglion cells of the cat},
author = {Enroth-Cugell, Christina and Robson, J G},
journal = {The Journal of Physiology},
issn = {0022-3751},
doi = {10.1113/jphysiol.1966.sp008107},
pmid = {16783910},
pages = {517--552},
number = {3},
volume = {187},
keywords = {},
}
@article{2015.Fei-Fei.Russakovsky,
year = {2015},
title = {ImageNet Large Scale Visual Recognition Challenge},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
journal = {International Journal of Computer Vision},
issn = {0920-5691},
doi = {10.1007/s11263-015-0816-y},
pages = {211--252},
number = {3},
volume = {115},
}
@article{2019.Maszke.Wołczyk,
year = {2019},
title = {Biologically-Inspired Spatial Neural Networks},
author = {Wołczyk, Maciej and Tabor, Jacek and Śmieja, Marek and Maszke, Szymon},
journal = {arXiv},
eprint = {1910.02776},
keywords = {},
}
@article{2018.Kriegeskorte.Kietzmann,
year = {2017},
rating = {0},
title = {Deep Neural Networks In Computational Neuroscience},
author = {Kietzmann, Tim C and McClure, Patrick and Kriegeskorte, Nikolaus},
journal = {bioRxiv},
doi = {10.1101/133504},
pages = {133504},
language = {English},
keywords = {},
month = {05},
}
@article{2020.Ma.Chen,
year = {2020},
title = {Self-training Avoids Using Spurious Features Under Domain Shift},
author = {Chen, Yining and Wei, Colin and Kumar, Ananya and Ma, Tengyu},
journal = {arXiv},
eprint = {2006.10032},
keywords = {},
}
@article{2020.Valle.Douillard,
year = {2020},
title = {PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning},
author = {Douillard, Arthur and Cord, Matthieu and Ollion, Charles and Robert, Thomas and Valle, Eduardo},
journal = {arXiv},
eprint = {2004.13513},
keywords = {},
}
@article{1998.Thrun.Thrun,
year = {1998},
title = {Learning to Learn},
author = {Thrun, Sebastian},
doi = {10.1007/978-1-4615-5529-2\_8},
pages = {181--209},
}
@article{2016.Alonso.Kremkow,
year = {2016},
rating = {0},
title = {Principles underlying sensory map topography in primary visual cortex},
author = {Kremkow, Jens and Jin, Jianzhong and Wang, Yushi and Alonso, Jose M},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature17936},
pmid = {27120164},
pmcid = {PMC4860131},
url = {https://www.nature.com/nature/journal/v533/n7601/pdf/nature17936.pdf},
pages = {52--57},
number = {7601},
volume = {533},
language = {English},
keywords = {},
month = {04},
}
@article{2018.Shafait.Javed,
year = {2018},
title = {Revisiting Distillation and Incremental Classifier Learning},
author = {Javed, Khurram and Shafait, Faisal},
journal = {arXiv},
eprint = {1807.02802},
keywords = {},
}
@article{1976.Boyes-Braem.Rosch,
year = {1976},
title = {Basic objects in natural categories},
author = {Rosch, Eleanor and Mervis, Carolyn B and Gray, Wayne D and Johnson, David M and Boyes-Braem, Penny},
journal = {Cognitive Psychology},
issn = {0010-0285},
doi = {10.1016/0010-0285(76)90013-x},
pages = {382--439},
number = {3},
volume = {8},
keywords = {},
}
@article{2016.Cusack.Mitchell,
year = {2016},
rating = {0},
title = {Semantic and emotional content of imagined representations in human occipitotemporal cortex},
author = {Mitchell, Daniel J and Cusack, Rhodri},
journal = {Scientific Reports},
doi = {10.1038/srep20232},
pmid = {26839123},
pmcid = {PMC4738308},
pages = {20232},
number = {1},
volume = {6},
language = {English},
keywords = {},
month = {02},
}
@article{2012.Forsyth.Wang,
year = {2012},
title = {Learning Image Similarity from Flickr Groups Using Fast Kernel Machines},
author = {Wang, Gang and Hoiem, Derek and Forsyth, David},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2012.29},
pmid = {22997127},
pages = {2177--2188},
number = {11},
volume = {34},
}
@article{2021.Tuytelaars.Delange,
year = {2021},
title = {A continual learning survey: Defying forgetting in classification tasks},
author = {Delange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Greg and Tuytelaars, Tinne},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2021.3057446},
pmid = {33544669},
eprint = {1909.08383},
pages = {1--1},
number = {99},
volume = {PP},
keywords = {},
}
@article{2000.Abbott.Song,
year = {2000},
title = {Competitive Hebbian learning through spike-timing-dependent synaptic plasticity},
author = {Song, Sen and Miller, Kenneth D and Abbott, L F},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/78829},
pmid = {10966623},
pages = {919--926},
number = {9},
volume = {3},
keywords = {},
}
@article{1984.Venzon.Moolgavkar,
year = {1984-09},
rating = {0},
title = {A Geometric Approach to Nonlinear Regression Diagnostics with Applications to matched Case-Control Studies},
author = {Moolgavkar, Suresh H and Lustbader, Edward D and Venzon, David J},
journal = {The Annals of Statistics},
issn = {0090-5364},
doi = {10.1214/aos/1176346704},
pages = {816--826},
number = {3},
volume = {12},
language = {English},
keywords = {},
}
@article{2017.Girshick.Hariharan,
year = {2017},
title = {Low-Shot Visual Recognition by Shrinking and Hallucinating Features},
author = {Hariharan, Bharath and Girshick, Ross},
journal = {2017 IEEE International Conference on Computer Vision (ICCV)},
doi = {10.1109/iccv.2017.328},
pages = {3037--3046},
}
@article{2017.Botvinick.Hassabis,
year = {2017-07},
rating = {0},
title = {Neuroscience-Inspired Artificial Intelligence.},
author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
journal = {Neuron},
issn = {0896-6273},
doi = {10.1016/j.neuron.2017.06.011},
pmid = {28728020},
url = {http://www.cell.com/neuron/pdf/S0896-6273(17)30509-3.pdf},
pages = {245--258},
number = {2},
volume = {95},
language = {English},
keywords = {},
}
@article{2017.Livingstone.Arcaro,
year = {2017},
rating = {0},
title = {Retinotopic Organization of Scene Areas in Macaque Inferior Temporal Cortex},
author = {Arcaro, Michael J and Livingstone, Margaret S},
journal = {The Journal of Neuroscience},
issn = {0270-6474},
doi = {10.1523/jneurosci.0569-17.2017},
pmid = {28674177},
pages = {7373--7389},
number = {31},
volume = {37},
language = {English},
keywords = {},
month = {08},
}
@article{2000.Katz.Crowley,
year = {2000},
title = {Early Development of Ocular Dominance Columns},
author = {Crowley, Justin C. and Katz, Lawrence C.},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.290.5495.1321},
pmid = {11082053},
pages = {1321--1324},
number = {5495},
volume = {290},
keywords = {},
}
@article{2011.Szepesvari.Abbasi-Yadkori,
year = {2011},
title = {Online Least Squares Estimation with Self-Normalized Processes: An Application to Bandit Problems},
author = {Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
journal = {arXiv},
eprint = {1102.2670},
keywords = {},
}
@article{2016.Freitas.Shahriari,
year = {2016},
rating = {0},
title = {Taking the Human Out of the Loop - A Review of Bayesian Optimization.},
author = {Shahriari, Bobak and Swersky, Kevin and 0001, Ziyu Wang and Adams, Ryan P and Freitas, Nando de},
journal = {Proceedings of the IEEE},
keywords = {},
}
@article{2017.Krishnamurthy.Sinha,
year = {2017},
title = {Introspection: Accelerating Neural Network Training By Learning Weight Evolution},
author = {Sinha, Abhishek and Sarkar, Mausoom and Mukherjee, Aahitagni and Krishnamurthy, Balaji},
journal = {arXiv},
doi = {10.48550/arxiv.1704.04959},
eprint = {1704.04959},
abstract = {Neural Networks are function approximators that have achieved state-of-the-art accuracy in numerous machine learning tasks. In spite of their great success in terms of accuracy, their large training time makes it difficult to use them for various tasks. In this paper, we explore the idea of learning weight evolution pattern from a simple network for accelerating training of novel neural networks. We use a neural network to learn the training pattern from MNIST classification and utilize it to accelerate training of neural networks used for CIFAR-10 and ImageNet classification. Our method has a low memory footprint and is computationally efficient. This method can also be used with other optimizers to give faster convergence. The results indicate a general trend in the weight evolution during training of neural networks.}
}
@article{2017.Vedaldi.Rebuffi,
year = {2017},
title = {Learning multiple visual domains with residual adapters},
author = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
journal = {arXiv},
doi = {10.48550/arxiv.1705.08045},
eprint = {1705.08045},
abstract = {There is a growing interest in learning data representations that work well for many different types of problems and data. In this paper, we look in particular at the task of learning a single visual representation that can be successfully utilized in the analysis of very different types of images, from dog breeds to stop signs and digits. Inspired by recent work on learning networks that predict the parameters of another, we develop a tunable deep network architecture that, by means of adapter residual modules, can be steered on the fly to diverse visual domains. Our method achieves a high degree of parameter sharing while maintaining or even improving the accuracy of domain-specific representations. We also introduce the Visual Decathlon Challenge, a benchmark that evaluates the ability of representations to capture simultaneously ten very different visual domains and measures their ability to recognize well uniformly.}
}
@article{2018.Belongie.Horn,
year = {2018},
title = {The iNaturalist Species Classification and Detection Dataset},
author = {Horn, Grant Van and Aodha, Oisin Mac and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.2018.00914},
pages = {8769--8778}
}
@article{2016.Han.Noh,
year = {2016},
title = {Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction},
author = {Noh, Hyeonwoo and Seo, Paul Hongsuck and Han, Bohyung},
journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2016.11},
pages = {30--38},
}
@article{2019.Chandraker.Yin,
year = {2019},
title = {Feature Transfer Learning for Face Recognition with Under-Represented Data},
author = {Yin, Xi and Yu, Xiang and Sohn, Kihyuk and Liu, Xiaoming and Chandraker, Manmohan},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.00585},
pages = {5697--5706},
volume = {00},
}
@article{2017.Yu.Munkhdalai,
year = {2017},
title = {Meta Networks.},
author = {Munkhdalai, Tsendsuren and Yu, Hong},
journal = {Proceedings of machine learning research},
pmid = {31106300},
pmcid = {PMC6519722},
pages = {2554--2563},
volume = {70}
}
@article{2018.Chen.Geng,
year = {2018},
title = {Recent Advances in Open Set Recognition: A Survey},
author = {Geng, Chuanxing and Huang, Sheng-Jun and Chen, Songcan},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2020.2981604},
pmid = {32191881},
eprint = {1811.08581},
pages = {3614--3631},
number = {10},
volume = {43},
keywords = {},
}
@article{2020.Sun.Liu,
year = {2020},
title = {Mnemonics Training: Multi-Class Incremental Learning without Forgetting},
author = {Liu, Yaoyao and Su, Yuting and Liu, An-An and Schiele, Bernt and Sun, Qianru},
journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr42600.2020.01226},
eprint = {2002.10211},
pages = {12242--12251},
volume = {00},
keywords = {},
}
@article{2012.Krause.Chen,
year = {2012},
rating = {0},
title = {Joint Optimization and Variable Selection of High-dimensional Gaussian Processes},
author = {Chen, Bo and Castro, Rui and Krause, Andreas},
journal = {arXiv},
eprint = {1206.6396},
volume = {cs.LG},
keywords = {},
}
@article{2014.Boult.Scheirer,
year = {2014},
title = {Probability Models for Open Set Recognition},
author = {Scheirer, Walter J. and Jain, Lalit P. and Boult, Terrance E.},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2014.2321392},
pmid = {26353070},
pages = {2317--2324},
number = {11},
volume = {36},
keywords = {}
}
@article{1992.Kiorpes.Kiorpes,
year = {2009},
rating = {0},
title = {Development of vernier acuity and grating acuity in normally reared monkeys},
author = {Kiorpes, Lynne},
journal = {Visual Neuroscience},
issn = {0952-5238},
doi = {10.1017/s0952523800010658},
pmid = {1390384},
pages = {243--251},
number = {3-4},
volume = {9},
language = {English},
keywords = {},
month = {06}
}
@article{2020.Krause.Dhall,
year = {2020},
title = {Hierarchical Image Classification using Entailment Cone Embeddings},
author = {Dhall, Ankit and Makarova, Anastasia and Ganea, Octavian and Pavllo, Dario and Greeff, Michael and Krause, Andreas},
journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
doi = {10.1109/cvprw50498.2020.00426},
pages = {3649--3658},
volume = {00},
keywords = {},
}
@article{2017.Avella-Medina.Avella-Medina,
year = {2017},
title = {Influence functions for penalized M-estimators},
author = {Avella-Medina, Marco},
journal = {Bernoulli},
issn = {1350-7265},
doi = {10.3150/16-bej841},
pages = {3178--3196},
number = {4B},
volume = {23},
keywords = {},
}
@article{2017.Gershman.Stachenfeld,
year = {2017},
rating = {0},
title = {The hippocampus as a predictive map},
author = {Stachenfeld, Kimberly L and Botvinick, Matthew M and Gershman, Samuel J},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/nn.4650},
pmid = {28967910},
pages = {1643--1653},
number = {11},
volume = {20},
keywords = {},
month = {10},
}
@article{2022.Kong.Alshammari,
year = {2022},
title = {Long- Tailed Recognition via Weight Balancing},
author = {Alshammari, Shaden and Wang, Yu-Xiong and Ramanan, Deva and Kong, Shu},
journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr52688.2022.00677},
pages = {6887--6897},
volume = {00},
}
@article{2012.Zisserman.Aytar,
year = {2012},
title = {Enhancing Exemplar SVMs using Part Level Transfer Regularization},
author = {Aytar, Yusuf and Zisserman, Andrew},
journal = {Procedings of the British Machine Vision Conference 2012},
doi = {10.5244/c.26.79},
pages = {79.1--79.11},
}
@article{2021.Han.Hwang,
year = {2021},
title = {Exemplar-Based Open-Set Panoptic Segmentation Network},
author = {Hwang, Jaedong and Oh, Seoung Wug and Lee, Joon-Young and Han, Bohyung},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00123},
pages = {1175--1184},
volume = {00},
keywords = {},
}
@article{2017.Kanan.Kemker,
year = {2017},
title = {FearNet: Brain-Inspired Model for Incremental Learning},
author = {Kemker, Ronald and Kanan, Christopher},
journal = {arXiv},
eprint = {1711.10563},
keywords = {},
}
@article{2003.O'Leary.McLaughlin,
year = {2003},
title = {Retinotopic Map Refinement Requires Spontaneous Retinal Waves during a Brief Critical Period of Development},
author = {McLaughlin, Todd and Torborg, Christine L and Feller, Marla B and O'Leary, Dennis D M},
journal = {Neuron},
issn = {0896-6273},
doi = {10.1016/s0896-6273(03)00790-6},
pmid = {14687549},
pages = {1147--1160},
number = {6},
volume = {40},
keywords = {},
}
@article{2020.Tsao.Bao,
year = {2020},
title = {A map of object space in primate inferotemporal cortex},
author = {Bao, Pinglei and She, Liang and McGill, Mason and Tsao, Doris Y},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/s41586-020-2350-5},
pmid = {32494012},
pages = {1--6},
keywords = {},
}
@techreport{2007.Poggio.Masquelier,
year = {2007},
rating = {0},
author = {Masquelier, Timothée and Serre, Thomas and Thorpe, Simon and Poggio, Tomaso},
title = {Learning Complex Cell Invariance from Natural Videos: A Plausibility Proof},
url = {https://dspace.mit.edu/bitstream/handle/1721.1/39833/MIT-CSAIL-TR-2007-060.pdf},
keywords = {},
}
@article{2019.Lin.Hou,
year = {2019},
title = {Learning a Unified Classifier Incrementally via Rebalancing},
author = {Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.00092},
pages = {831--839},
volume = {00},
keywords = {},
}
@article{2018.Lillicrap.Bartunov,
year = {2018},
title = {Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures},
author = {Bartunov, Sergey and Santoro, Adam and Richards, Blake A and Marris, Luke and Hinton, Geoffrey E and Lillicrap, Timothy},
journal = {arXiv},
eprint = {1807.04587},
keywords = {},
}
@article{2021.Sun.Zhang,
year = {2021},
title = {Distribution Alignment: A Unified Framework for Long-tail Visual Recognition},
author = {Zhang, Songyang and Li, Zeming and Yan, Shipeng and He, Xuming and Sun, Jian},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00239},
pages = {2361--2370},
volume = {00},
keywords = {}
}
@article{2016.Fitzpatrick.Lee,
year = {2016},
rating = {0},
title = {Topology of ON and OFF inputs in visual cortex enables an invariant columnar architecture},
author = {Lee, Kuo-Sheng and Huang, Xiaoying and Fitzpatrick, David},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature17941},
pmid = {27120162},
url = {https://www.nature.com/nature/journal/v533/n7601/pdf/nature17941.pdf},
pages = {90--94},
number = {7601},
volume = {533},
language = {English},
keywords = {},
month = {04},
}
@article{2017.Zemel.Snell,
year = {2017},
title = {Prototypical Networks for Few-shot Learning},
author = {Snell, Jake and Swersky, Kevin and Zemel, Richard S},
journal = {arXiv},
doi = {10.48550/arxiv.1703.05175},
eprint = {1703.05175},
abstract = {We propose prototypical networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results. We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. We further extend prototypical networks to zero-shot learning and achieve state-of-the-art results on the CU-Birds dataset.}
}
@article{2017.Tamaazousti.Tamaazousti,
year = {2017},
title = {Learning More Universal Representations for Transfer-Learning},
author = {Tamaazousti, Youssef and Borgne, Hervé Le and Hudelot, Céline and Seddik, Mohamed El Amine and Tamaazousti, Mohamed},
journal = {arXiv},
eprint = {1712.09708},
keywords = {},
}
@article{2011.Vazquez.Benassi,
year = {2011},
rating = {0},
title = {Robust Gaussian Process-Based Global Optimization Using a Fully Bayesian Expected Improvement Criterion},
author = {Benassi, Romain and Bect, Julien and Vazquez, Emmanuel},
journal = {LION},
issn = {0302-9743},
doi = {10.1007/978-3-642-25566-3\_13},
pages = {176--190},
number = {4},
volume = {6683},
keywords = {},
}
@article{2014.Boult.Jain,
year = {2014},
title = {Computer Vision – ECCV 2014, 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part III},
author = {Jain, Lalit P. and Scheirer, Walter J. and Boult, Terrance E.},
journal = {Lecture Notes in Computer Science},
issn = {0302-9743},
doi = {10.1007/978-3-319-10578-9\_26},
pages = {393--409},
keywords = {},
}
@article{2017.Livingstone.Arcaro3,
year = {2017},
rating = {0},
title = {Seeing faces is necessary for face-domain formation},
author = {Arcaro, Michael J and Schade, Peter F and Vincent, Justin L and Ponce, Carlos R and Livingstone, Margaret S},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/nn.4635},
pmid = {28869581},
pages = {1404--1412},
number = {10},
volume = {20},
keywords = {},
month = {09},
}
@article{2015.Boult.Bendale,
year = {2015},
title = {Towards Open World Recognition},
author = {Bendale, Abhijit and Boult, Terrance},
journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2015.7298799},
eprint = {1412.5687},
pages = {1893--1902},
keywords = {},
}
@article{2012.Garivier.Kaufmann,
year = {2012},
rating = {0},
title = {On Bayesian Upper Confidence Bounds for Bandit Problems.},
author = {Kaufmann, Emilie and Cappé, Olivier and Garivier, Aurélien},
journal = {AISTATS},
keywords = {},
}
@article{2021.Agu.Buquicchio,
year = {2021},
title = {Variational Open Set Recognition (VOSR)},
author = {Buquicchio, Luke and Gerych, Walter and Alajaji, Abdulaziz and Chandrasekaran, Kavin and Mansoor, Hamid and Hartvigsen, Thomas and Rundensteiner, Elke and Agu, Emmanuel},
journal = {2021 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/bigdata52589.2021.9671727},
pages = {994--1001},
volume = {00},
keywords = {},
}
@article{1991.Schechtman.Schechtman,
year = {1991-05},
rating = {0},
title = {On Estimating the Asymptotic Variance of a Function of U Statistics},
author = {Schechtman, Edna},
journal = {The American Statistician},
issn = {0003-1305},
doi = {10.2307/2684368},
pages = {103},
number = {2},
volume = {45},
keywords = {},
}
@article{2011.Bull.Bull,
year = {2011},
rating = {0},
title = {Convergence rates of efficient global optimization algorithms},
author = {Bull, Adam D},
journal = {arXiv},
eprint = {1101.3501},
volume = {stat.ML},
keywords = {},
}
@article{2003.Meister.Ölveczky,
year = {2003},
title = {Segregation of object and background motion in the retina},
author = {Ölveczky, Bence P and Baccus, Stephen A and Meister, Markus},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/nature01652},
pmid = {12754524},
pages = {401--408},
number = {6938},
volume = {423},
keywords = {},
}
@article{2008.Barrett.Adair,
year = {2008-10},
rating = {0},
title = {Spatial Neglect: Clinical and Neuroscience Review},
author = {Adair, John C and Barrett, Anna M},
journal = {Annals of the New York Academy of Sciences},
issn = {0077-8923},
doi = {10.1196/annals.1444.008},
pmid = {18990119},
pmcid = {PMC2962986},
pages = {21--43},
number = {1},
volume = {1142},
language = {English},
keywords = {},
}
@article{2013.Wang.Tong,
year = {2013},
rating = {0},
title = {Optimal variance estimation without estimating the mean function},
author = {Tong, Tiejun and Ma, Yanyuan and Wang, Yuedong},
journal = {Bernoulli},
issn = {1350-7265},
doi = {10.3150/12-bej432},
eprint = {1312.3046},
url = {arXiv.org},
pages = {1839--1854},
number = {5A},
volume = {19},
language = {English},
note = {Published in at http://dx.doi.org/10.3150/12-BEJ432 the Bernoulli (http://isi.cbs.nl/bernoulli/) by the International Statistical Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)},
keywords = {},
month = {12},
}
@article{2022.Ferrante.Lara,
year = {2022},
title = {Addressing fairness in artificial intelligence for medical imaging},
author = {Lara, María Agustina Ricci and Echeveste, Rodrigo and Ferrante, Enzo},
journal = {Nature Communications},
doi = {10.1038/s41467-022-32186-3},
pmid = {35933408},
pmcid = {PMC9357063},
pages = {4581},
number = {1},
volume = {13}
}
@article{2015.Berg.Ordonez,
year = {2015},
title = {Predicting Entry-Level Categories},
author = {Ordonez, Vicente and Liu, Wei and Deng, Jia and Choi, Yejin and Berg, Alexander C. and Berg, Tamara L.},
journal = {International Journal of Computer Vision},
issn = {0920-5691},
doi = {10.1007/s11263-015-0815-z},
pages = {29--43},
number = {1},
volume = {115},
keywords = {},
}
@article{2021.Wang.Guo,
year = {2021},
title = {Long-Tailed Multi-Label Visual Recognition by Collaborative Training on Uniform and Re-balanced Samplings},
author = {Guo, Hao and Wang, Song},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.01484},
pages = {15084--15093},
volume = {00},
keywords = {}
}
@article{2014.Adam.Deng,
year = {2014},
title = {Computer Vision – ECCV 2014},
author = {Deng, Jia and Ding, Nan and Jia, Yangqing and Frome, Andrea and Murphy, Kevin and Bengio, Samy and Li, Yuan and Neven, Hartmut and Adam, Hartwig},
journal = {Lecture Notes in Computer Science},
issn = {0302-9743},
doi = {10.1007/978-3-319-10590-1\_4},
pages = {48--64},
keywords = {},
}
@article{2009.Kornprobst.Escobar,
year = {2009},
rating = {0},
title = {Action Recognition Using a Bio-Inspired Feedforward Spiking Network},
author = {Escobar, Maria-Jose and Masson, Guillaume S and Vieville, Thierry and Kornprobst, Pierre},
journal = {International Journal of Computer Vision},
issn = {0920-5691},
doi = {10.1007/s11263-008-0201-1},
url = {ftp://ftp-sop.inria.fr/neuromathcomp/publications/2009/escobar-masson-etal:09.pdf},
pages = {284--301},
number = {3},
volume = {82},
language = {English},
keywords = {},
}
@article{2019.Zhu.Huangnar,
year = {2019},
title = {Unsupervised Deep Learning by Neighbourhood Discovery},
author = {Huang, Jiabo and Dong, Qi and Gong, Shaogang and Zhu, Xiatian},
journal = {arXiv},
eprint = {1904.11567},
keywords = {}
}
@article{2018.Lillicrap.Rae,
year = {2018},
title = {Fast Parametric Learning with Activation Memorization},
author = {Rae, Jack W and Dyer, Chris and Dayan, Peter and Lillicrap, Timothy P},
journal = {arXiv},
eprint = {1803.10049},
keywords = {},
}
@article{2015.Bury.Amaran,
year = {2017},
rating = {0},
title = {Simulation optimization: a review of algorithms and applications},
author = {Amaran, Satyajith and Sahinidis, Nikolaos V and Sharda, Bikram and Bury, Scott J},
journal = {Annals of Operations Research},
issn = {0254-5330},
doi = {10.1007/s10479-015-2019-x},
eprint = {1706.08591},
pages = {351--380},
number = {1},
volume = {240},
language = {English},
keywords = {},
}
@article{1984.Kosslyn.Jolicoeur,
year = {1984},
title = {Pictures and names: Making the connection},
author = {Jolicoeur, Pierre and Gluck, Mark A. and Kosslyn, Stephen M.},
journal = {Cognitive Psychology},
issn = {0010-0285},
doi = {10.1016/0010-0285(84)90009-4},
pmid = {6734136},
pages = {243--275},
number = {2},
volume = {16},
keywords = {},
}
@article{2012.Cesa-Bianchi.Bubeck,
year = {2012},
rating = {0},
title = {Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems},
author = {Bubeck, Sébastien and Cesa-Bianchi, Nicolò},
journal = {arXiv},
eprint = {1204.5721},
url = {arXiv.org},
volume = {cs.LG},
note = {To appear in Foundations and Trends in Machine Learning},
keywords = {},
month = {04},
}
@article{2017.Roy.Panda,
year = {2017},
title = {Learning to Generate Sequences with Combination of Hebbian and Non-hebbian Plasticity in Recurrent Spiking Neural Networks.},
author = {Panda, Priyadarshini and Roy, Kaushik},
journal = {Frontiers in neuroscience},
issn = {1662-4548},
doi = {10.3389/fnins.2017.00693},
pmid = {29311774},
pages = {693},
volume = {11},
keywords = {},
}
@article{2016.Talwalkar.Li,
year = {2016},
rating = {0},
title = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
journal = {arXiv},
eprint = {1603.06560},
url = {arXiv.org},
volume = {cs.LG},
note = {Changes: - Improved exposition and theoretical results - Additional experiments: deep learning experiments, kernel classification, random features classification - Small edit to Related Works section},
keywords = {},
month = {03},
}
@article{2001.Ziv.Strauss,
year = {2001},
title = {Children request teaching when asking for names of objects},
author = {Strauss, Sidney and Ziv, Margalit},
journal = {Behavioral and Brain Sciences},
issn = {1469-1825},
doi = {10.1017/s0140525x01380135},
pmid = {18241411},
pages = {1118--1119},
number = {6},
volume = {24},
keywords = {},
}
@article{2018.Liu.Tanos,
year = {2018},
title = {A Survey on Deep Transfer Learning},
author = {Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
journal = {arXiv},
eprint = {1808.01974},
keywords = {}
}
@article{2017.Hebert.Wangpln,
year = {2017},
title = {Learning to model the tail},
author = {Wang, Yu-Xiong and Ramanan, Deva and Hebert, Martial},
journal = {Advances in neural information processing systems},
volume = {30},
}
@article{2008.Suykens.Debruyne,
year = {2008-10},
rating = {0},
title = {Model Selection in Kernel Based Regression using the Influence Function},
author = {Debruyne, Michiel and Hubert, Mia and Suykens, Johan},
journal = {Journal of Machine Learning Research},
url = {http://www.jmlr.org/papers/volume9/debruyne08a/debruyne08a.pdf},
keywords = {},
}
@article{1959.Pitts.Lettvin,
year = {1959},
title = {What the Frog's Eye Tells the Frog's Brain},
author = {Lettvin, J and Maturana, H and McCulloch, W and Pitts, W},
journal = {Proceedings of the IRE},
issn = {0096-8390},
doi = {10.1109/jrproc.1959.287207},
pages = {1940--1951},
number = {11},
volume = {47},
keywords = {},
}
@article{2014.Freitas.Wang,
year = {2014},
rating = {0},
title = {Theoretical Analysis of Bayesian Optimisation with Unknown Gaussian Process Hyper-Parameters},
author = {Wang, Ziyu and Freitas, Nando de},
journal = {arXiv},
eprint = {1406.7758},
volume = {stat.ML},
keywords = {},
}
@article{1992.Redlich.Atick,
year = {1992},
title = {What Does the Retina Know about Natural Scenes?},
author = {Atick, Joseph J and Redlich, A Norman},
journal = {Neural Computation},
issn = {0899-7667},
doi = {10.1162/neco.1992.4.2.196},
pages = {196--210},
number = {2},
volume = {4},
keywords = {},
}
@article{2016.Wierstra.Vinyals,
year = {2016},
title = {Matching Networks for One Shot Learning},
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
journal = {arXiv},
doi = {10.48550/arxiv.1606.04080},
eprint = {1606.04080},
abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6\% to 93.2\% and from 88.0\% to 93.8\% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.}
}
@article{1991.Taylor.Tanaka,
year = {1991},
title = {Object categories and expertise: Is the basic level in the eye of the beholder?},
author = {Tanaka, James W and Taylor, Marjorie},
journal = {Cognitive Psychology},
issn = {0010-0285},
doi = {10.1016/0010-0285(91)90016-h},
pages = {457--482},
number = {3},
volume = {23},
keywords = {},
}
@article{2020.Wang.Lilwp,
year = {2020},
title = {On Deep Unsupervised Active Learning},
author = {Li, Changsheng and Ma, Handong and Kang, Zhao and Yuan, Ye and Zhang, Xiao-Yu and Wang, Guoren},
journal = {arXiv},
eprint = {2007.13959},
keywords = {}
}
@article{2021.Baraniuk.You,
year = {2021},
title = {Max-Affine Spline Insights Into Deep Network Pruning},
author = {You, Haoran and Balestriero, Randall and Lu, Zhihan and Kou, Yutong and Shi, Huihong and Zhang, Shunyao and Wu, Shang and Lin, Yingyan and Baraniuk, Richard},
journal = {arXiv},
doi = {10.48550/arxiv.2101.02338},
eprint = {2101.02338},
keywords = {}
}
@article{1996.Wheat.Ferster,
year = {1996},
title = {Orientation selectivity of thalamic input to simple cells of cat visual cortex},
author = {Ferster, David and Chung, Sooyoung and Wheat, Heidi},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/380249a0},
pmid = {8637573},
pages = {249--252},
number = {6571},
volume = {380},
keywords = {},
}
@article{1947.Mises.Mises,
year = {1947},
title = {On the Asymptotic Distribution of Differentiable Statistical Functions},
author = {Mises, R. v.},
journal = {The Annals of Mathematical Statistics},
issn = {0003-4851},
doi = {10.1214/aoms/1177730385},
pages = {309--348},
number = {3},
volume = {18},
keywords = {},
}
@article{2016.Larochelle.Ravi,
year = {2016},
title = {Optimization as a model for few-shot learning},
author = {Ravi, Sachin and Larochelle, Hugo},
}
@article{2020.Makedon.Jaiswalzfj,
year = {2020},
title = {A Survey on Contrastive Self-Supervised Learning},
author = {Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
journal = {Technologies},
doi = {10.3390/technologies9010002},
pages = {2},
number = {1},
volume = {9},
keywords = {},
}
@article{1997.Caruana.Caruana,
year = {1997},
title = {Multitask Learning},
author = {Caruana, Rich},
journal = {Machine Learning},
issn = {0885-6125},
doi = {10.1023/a:1007379606734},
pages = {41--75},
number = {1},
volume = {28}
}
@article{1978.Smith.Robbins,
year = {1978},
title = {The genesis and use of exemplar vs. prototype knowledge in abstract category learning},
author = {Robbins, Donald and Barresi, John and Compton, Philip and Furst, Arthur and Russo, May and Smith, Margaret Ann},
journal = {Memory \& Cognition},
issn = {0090-502X},
doi = {10.3758/bf03197481},
pages = {473--480},
number = {4},
volume = {6},
keywords = {},
}
@article{2018.Levine.Finn,
year = {2018},
title = {Probabilistic Model-Agnostic Meta-Learning},
author = {Finn, Chelsea and Xu, Kelvin and Levine, Sergey},
journal = {arXiv},
doi = {10.48550/arxiv.1806.02817},
eprint = {1806.02817},
abstract = {Meta-learning for few-shot learning entails acquiring a prior over previous tasks and experiences, such that new tasks be learned from small amounts of data. However, a critical challenge in few-shot learning is task ambiguity: even when a powerful prior can be meta-learned from a large number of prior tasks, a small dataset for a new task can simply be too ambiguous to acquire a single model (e.g., a classifier) for that task that is accurate. In this paper, we propose a probabilistic meta-learning algorithm that can sample models for a new task from a model distribution. Our approach extends model-agnostic meta-learning, which adapts to new tasks via gradient descent, to incorporate a parameter distribution that is trained via a variational lower bound. At meta-test time, our algorithm adapts via a simple procedure that injects noise into gradient descent, and at meta-training time, the model is trained such that this stochastic adaptation procedure produces samples from the approximate model posterior. Our experimental results show that our method can sample plausible classifiers and regressors in ambiguous few-shot learning problems. We also show how reasoning about ambiguity can also be used for downstream active learning problems.}
}
@article{2001.Noë.O'Regan,
year = {2001},
title = {A sensorimotor account of vision and visual consciousness},
author = {O'Regan, J Kevin and Noë, Alva},
journal = {Behavioral and Brain Sciences},
issn = {0140-525X},
doi = {10.1017/s0140525x01000115},
pmid = {12239892},
pages = {939--973},
number = {5},
volume = {24},
keywords = {},
}
@article{2016.Sha.Changpinyo,
year = {2016},
title = {Synthesized Classifiers for Zero-Shot Learning},
author = {Changpinyo, Soravit and Chao, Wei-Lun and Gong, Boqing and Sha, Fei},
journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2016.575},
pages = {5327--5336},
}
@article{2019.Yu.Xu,
year = {2019},
title = {Open-world Learning and Application to Product Classification},
author = {Xu, Hu and Liu, Bing and Shu, Lei and Yu, P.},
journal = {The World Wide Web Conference on - WWW '19},
doi = {10.1145/3308558.3313644},
eprint = {1809.06004},
pages = {3413--3419},
keywords = {},
}
@article{2000.Cook.Cook,
year = {2000},
rating = {0},
title = {Detection of Influential Observation in Linear Regression},
author = {Cook, R Dennis},
journal = {Technometrics},
issn = {0040-1706},
doi = {10.1080/00401706.2000.10485981},
pages = {65--68},
number = {1},
volume = {42},
language = {English},
keywords = {},
}
@article{1993.Collingridge.Bliss,
year = {1993},
title = {A synaptic model of memory: long-term potentiation in the hippocampus},
author = {Bliss, T V P and Collingridge, G L},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/361031a0},
pmid = {8421494},
pages = {31--39},
number = {6407},
volume = {361},
keywords = {}
}
@article{1976.Webb.Sherman,
year = {1976},
title = {X- and Y-cells in the dorsal lateral geniculate nucleus of the owl monkey (Aotus trivirgatus)},
author = {Sherman, S and Wilson and Kaas, J and Webb, S},
journal = {Science},
issn = {0036-8075},
doi = {10.1126/science.816006},
pmid = {816006},
pages = {475--477},
number = {4238},
volume = {192},
keywords = {},
}
@article{1962.Wiesel.Hubel,
year = {1962},
title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
author = {Hubel, D H and Wiesel, T N},
journal = {The Journal of Physiology},
issn = {0022-3751},
doi = {10.1113/jphysiol.1962.sp006837},
pmid = {14449617},
pages = {106--154},
number = {1},
volume = {160},
keywords = {},
}
@article{2016.Hazan.Agarwal,
year = {2016},
rating = {0},
title = {Second-Order Stochastic Optimization for Machine Learning in Linear Time},
author = {Agarwal, Naman and Bullins, Brian and Hazan, Elad},
journal = {arXiv},
eprint = {1602.03943},
keywords = {},
}
@article{2020.Gong.Taodl,
year = {2020},
title = {Few-Shot Class-Incremental Learning},
author = {Tao, Xiaoyu and Hong, Xiaopeng and Chang, Xinyuan and Dong, Songlin and Wei, Xing and Gong, Yihong},
journal = {arXiv},
eprint = {2004.10956},
keywords = {},
}
@article{2016.Le.Ha,
year = {2016},
title = {HyperNetworks},
author = {Ha, David and Dai, Andrew and Le, Quoc V},
journal = {arXiv},
doi = {10.48550/arxiv.1609.09106},
eprint = {1609.09106},
abstract = {This work explores hypernetworks: an approach of using a one network, also known as a hypernetwork, to generate the weights for another network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve near state-of-the-art results on a variety of sequence modelling tasks including character-level language modelling, handwriting generation and neural machine translation, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.}
}
@article{2016.Lampert.Rebuffi,
year = {2016},
title = {iCaRL: Incremental Classifier and Representation Learning},
author = {Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
journal = {arXiv},
eprint = {1611.07725},
keywords = {},
}
@article{2002.Fischer.Auer,
year = {2002},
rating = {0},
title = {Finite-time Analysis of the Multiarmed Bandit Problem},
author = {Auer, Peter and Cesa-Bianchi, Nicolò and Fischer, Paul},
journal = {Machine Learning},
issn = {0885-6125},
doi = {10.1023/a:1013689704352},
pages = {235--256},
number = {2/3},
volume = {47},
keywords = {},
}
@article{2011.Bell.Ungerleider,
year = {2011-04},
rating = {0},
title = {Uncovering the visual “alphabet”: Advances in our understanding of object perception},
author = {Ungerleider, Leslie G and Bell, Andrew H},
journal = {Vision Research},
issn = {0042-6989},
doi = {10.1016/j.visres.2010.10.002},
pmid = {20971130},
pmcid = {PMC3208055},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3208055/pdf/nihms248899.pdf},
pages = {782--799},
number = {7},
volume = {51},
language = {English},
keywords = {},
}
@article{2017.Hebert.Misra,
year = {2017},
title = {From Red Wine to Red Tomato: Composition with Context},
author = {Misra, Ishan and Gupta, Abhinav and Hebert, Martial},
journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2017.129},
pages = {1160--1169},
}
@article{2021.Wu.Li,
year = {2021},
title = {Self Supervision to Distillation for Long-Tailed Visual Recognition},
author = {Li, Tianhao and Wang, Limin and Wu, Gangshan},
journal = {arXiv},
doi = {10.48550/arxiv.2109.04075},
eprint = {2109.04075},
abstract = {Deep learning has achieved remarkable progress for visual recognition on large-scale balanced datasets but still performs poorly on real-world long-tailed data. Previous methods often adopt class re-balanced training strategies to effectively alleviate the imbalance issue, but might be a risk of over-fitting tail classes. The recent decoupling method overcomes over-fitting issues by using a multi-stage training scheme, yet, it is still incapable of capturing tail class information in the feature learning stage. In this paper, we show that soft label can serve as a powerful solution to incorporate label correlation into a multi-stage training scheme for long-tailed recognition. The intrinsic relation between classes embodied by soft labels turns out to be helpful for long-tailed recognition by transferring knowledge from head to tail classes. Specifically, we propose a conceptually simple yet particularly effective multi-stage training scheme, termed as Self Supervised to Distillation (SSD). This scheme is composed of two parts. First, we introduce a self-distillation framework for long-tailed recognition, which can mine the label relation automatically. Second, we present a new distillation label generation module guided by self-supervision. The distilled labels integrate information from both label and data domains that can model long-tailed distribution effectively. We conduct extensive experiments and our method achieves the state-of-the-art results on three long-tailed recognition benchmarks: ImageNet-LT, CIFAR100-LT and iNaturalist 2018. Our SSD outperforms the strong LWS baseline by from \$2.7\textbackslash\%\$ to \$4.5\textbackslash\%\$ on various datasets. The code is available at https://github.com/MCG-NJU/SSD-LT.}
}
@article{1993.SHAH.BROMLEY,
year = {1993},
title = {SIGNATURE VERIFICATION USING A “SIAMESE” TIME DELAY NEURAL NETWORK},
author = {BROMLEY, JANE and BENTZ, JAMES W and BOTTOU, LÉON and GUYON, ISABELLE and LECUN, YANN and MOORE, CLIFF and SÄCKINGER, EDUARD and SHAH, ROOPAK},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
issn = {0218-0014},
doi = {10.1142/s0218001493000339},
pages = {669--688},
number = {04},
volume = {07},
}
@article{1999.Katz.Crowley,
year = {1999},
title = {Development of ocular dominance columns in the absence of retinal input},
author = {Crowley, Justin C and Katz, Lawrence C},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/16051},
pmid = {10570491},
pages = {1125--1130},
number = {12},
volume = {2},
keywords = {},
}
@article{2020.Girshick.He,
year = {2020},
title = {Momentum Contrast for Unsupervised Visual Representation Learning},
author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr42600.2020.00975},
pages = {9726--9735},
volume = {00},
keywords = {},
}
@article{2019.Zylberberg.Federer,
year = {2019},
title = {Training neural networks to mimic the brain improves object recognition performance},
author = {Federer, Callie and Xu, Haoyan and Fyshe, Alona and Zylberberg, Joel},
journal = {arXiv},
eprint = {1905.10679},
keywords = {},
}
@article{2021.Ramanan.Lin,
year = {2021},
title = {The CLEAR Benchmark: Continual LEArning on Real-World Imagery},
author = {Lin, Zhiqui and Shi, Jia and Pathak, Deepak and Ramanan, Deva},
keywords = {},
month = {8},
}
@article{2000.Auer.Auer,
year = {2002},
rating = {0},
title = {Using upper confidence bounds for online learning},
author = {Auer, P},
journal = {Proceedings 41st Annual Symposium on Foundations of Computer Science},
issn = {0272-5428},
doi = {10.1109/sfcs.2000.892116},
pages = {270--279},
keywords = {},
}
@incollection{2012.Marcus.Hu,
year = {2012},
title = {A Survey of Some Model-Based Methods for Global Optimization},
author = {Hu, Jiaqiao and Wang, Yongqiang and Zhou, Enlu and Fu, Michael C and Marcus, Steven I},
booktitle = {Optimization, Control, and Applications of Stochastic Systems},
isbn = {9780817683368},
pages = {157--179},
keywords = {},
doi = {10.1007/978-0-8176-8337-5\_10},
}
@article{2009.Zhao.Xu,
year = {2009},
title = {Advances in Knowledge Discovery and Data Mining, 13th Pacific-Asia Conference, PAKDD 2009 Bangkok, Thailand, April 27-30, 2009 Proceedings},
author = {Xu, Ye and Furao, Shen and Hasegawa, Osamu and Zhao, Jinxi},
journal = {Lecture Notes in Computer Science},
issn = {0302-9743},
doi = {10.1007/978-3-642-01307-2\_112},
pages = {1046--1053},
keywords = {},
}
@techreport{1984.Cook.Cook,
year = {1984},
rating = {0},
author = {Cook, R D},
title = {Assessment of Local Influence.},
keywords = {},
}
@article{2016.Hoiem.Li,
year = {2016},
title = {Learning without Forgetting},
author = {Li, Zhizhong and Hoiem, Derek},
journal = {arXiv},
doi = {10.48550/arxiv.1606.09282},
eprint = {1606.09282},
abstract = {When building a unified vision system or gradually adding new capabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network (CNN), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.}
}
@article{2019.Hopfield.Krotov,
year = {2019},
title = {Unsupervised learning by competing hidden units},
author = {Krotov, Dmitry and Hopfield, John J},
journal = {Proceedings of the National Academy of Sciences},
issn = {0027-8424},
doi = {10.1073/pnas.1820458116},
pmid = {30926658},
eprint = {1806.10181},
pages = {7723--7731},
number = {16},
volume = {116},
keywords = {},
}
@article{2018.Carneiro.Felix,
year = {2018},
title = {Multi-modal Cycle-consistent Generalized Zero-Shot Learning},
author = {Felix, Rafael and Kumar, B G Vijay and Reid, Ian and Carneiro, Gustavo},
journal = {arXiv},
eprint = {1808.00136},
keywords = {},
}
@article{2021.Li.Tan,
year = {2021},
title = {Equalization Loss v2: A New Gradient Balance Approach for Long-tailed Object Detection},
author = {Tan, Jingru and Lu, Xin and Zhang, Gang and Yin, Changqing and Li, Quanquan},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00173},
pages = {1685--1694},
volume = {00},
keywords = {}
}
@article{2010.Bect.Vazquez,
year = {2010-11},
rating = {0},
title = {Convergence properties of the expected improvement algorithm with fixed mean and covariance functions},
author = {Vazquez, Emmanuel and Bect, Julien},
journal = {Journal of Statistical Planning and Inference},
issn = {0378-3758},
doi = {10.1016/j.jspi.2010.04.018},
pages = {3088--3095},
number = {11},
volume = {140},
language = {English},
keywords = {},
}
@article{2018.Roy.Roy,
year = {2018},
title = {Tree-CNN: A Hierarchical Deep Convolutional Neural Network for Incremental Learning},
author = {Roy, Deboleena and Panda, Priyadarshini and Roy, Kaushik},
journal = {arXiv},
eprint = {1802.05800},
keywords = {},
}
@article{2019.Lucey.Chang,
year = {2019},
title = {Argoverse: 3D Tracking and Forecasting With Rich Maps},
author = {Chang, Ming-Fang and Ramanan, Deva and Hays, James and Lambert, John and Sangkloy, Patsorn and Singh, Jagjeet and Bak, Slawomir and Hartnett, Andrew and Wang, De and Carr, Peter and Lucey, Simon},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.00895},
pages = {8740--8749},
volume = {00},
}
@article{1993.Schmidhuber.Schmidhuber,
year = {1993},
title = {A neural network that embeds its own meta-levels},
author = {Schmidhuber, J.},
journal = {IEEE International Conference on Neural Networks},
doi = {10.1109/icnn.1993.298591},
pages = {407--412 vol.1},
}
@article{2017.Miconi.Miconi,
year = {2017},
title = {Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks},
author = {Miconi, Thomas},
journal = {eLife},
doi = {10.7554/elife.20899},
pmid = {28230528},
pages = {e20899},
volume = {6},
keywords = {},
}
@article{2017.Liang.Koh,
year = {2017},
rating = {0},
title = {Understanding Black-box Predictions via Influence Functions},
author = {Koh, Pang Wei and Liang, Percy},
journal = {arXiv},
eprint = {1703.04730},
volume = {stat.ML},
keywords = {},
}
@article{1998.Welch.Jones,
year = {1998},
rating = {0},
title = {Efficient Global Optimization of Expensive Black-Box Functions},
author = {Jones, Donald R and Schonlau, Matthias and Welch, William J},
journal = {Journal of Global Optimization},
issn = {0925-5001},
doi = {10.1023/a:1008306431147},
pages = {455--492},
number = {4},
volume = {13},
keywords = {},
}
@article{2013.Poggio.Anselmi,
year = {2013},
rating = {0},
title = {Unsupervised Learning of Invariant Representations in Hierarchical Architectures.},
author = {Anselmi, Fabio and Leibo, Joel Z and Rosasco, Lorenzo and Mutch, Jim and Tacchetti, Andrea and Poggio, Tomaso A},
journal = {CoRR},
keywords = {},
}
@article{2021.Balasubramanian.Joseph,
year = {2021},
title = {Towards Open World Object Detection},
author = {Joseph, K J and Khan, Salman and Khan, Fahad Shahbaz and Balasubramanian, Vineeth N},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00577},
pages = {5826--5836},
volume = {00},
keywords = {},
}
@article{1986.Salama.Blasdel,
year = {1986},
title = {Voltage-sensitive dyes reveal a modular organization in monkey striate cortex},
author = {Blasdel, Gary G and Salama, Guy},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/321579a0},
pmid = {3713842},
pages = {579--585},
number = {6070},
volume = {321},
keywords = {},
}
@article{2006.Tsiatis.Tsiatis,
year = {2006},
title = {Semiparametric Theory and Missing Data},
author = {Tsiatis, Anastasios A.},
doi = {10.1007/0-387-37345-4},
keywords = {},
}
@article{2005.Bradley.Born,
year = {2005},
rating = {0},
title = {Structure and Function of Visual Area MT},
author = {Born, Richard T and Bradley, David C},
journal = {Annual Review of Neuroscience},
issn = {0147-006X},
doi = {10.1146/annurev.neuro.26.041002.131052},
pmid = {16022593},
pages = {157--189},
number = {1},
volume = {28},
language = {English},
keywords = {},
month = {07},
}
@article{1997.Locatelli.Locatelli,
year = {1997},
rating = {0},
title = {Bayesian Algorithms for One-Dimensional Global Optimization},
author = {Locatelli, M},
journal = {Journal of Global Optimization},
issn = {0925-5001},
doi = {10.1023/a:1008294716304},
pages = {57--76},
number = {1},
volume = {10},
keywords = {},
}
@article{2020.Zhang.Chen,
year = {2020},
title = {Active Online Domain Adaptation},
author = {Chen, Yining and Luo, Haipeng and Ma, Tengyu and Zhang, Chicheng},
journal = {arXiv},
eprint = {2006.14481},
keywords = {},
}
@article{2016.Hebert.Wang,
year = {2016},
title = {Computer Vision – ECCV 2016, 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VI},
author = {Wang, Yu-Xiong and Hebert, Martial},
journal = {Lecture Notes in Computer Science},
issn = {0302-9743},
doi = {10.1007/978-3-319-46466-4\_37},
pages = {616--634},
}
@article{2020.Tian.Jing,
year = {2020},
title = {Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey},
author = {Jing, Longlong and Tian, Yingli},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2020.2992393},
pmid = {32386141},
pages = {1--1},
number = {99},
volume = {PP},
keywords = {}
}
@article{2019.Ortiz.Laflaquière,
year = {2019},
title = {Unsupervised Emergence of Egocentric Spatial Structure from Sensorimotor Prediction},
author = {Laflaquière, Alban and Ortiz, Michael Garcia},
eprint = {1906.01401},
keywords = {},
}
@article{2015.Adams.Snoek,
year = {2015},
rating = {0},
title = {Scalable Bayesian Optimization Using Deep Neural Networks},
author = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Md Mostofa Ali and Prabhat and Adams, Ryan P},
journal = {arXiv},
eprint = {1502.05700},
volume = {stat.ML},
keywords = {},
}
@article{2019.Wiskott.Melchior,
year = {2019},
title = {Hebbian-Descent},
author = {Melchior, Jan and Wiskott, Laurenz},
journal = {arXiv},
eprint = {1905.10585},
keywords = {},
}
@article{2019.Kanan.Hayes,
year = {2019},
title = {REMIND Your Neural Network to Prevent Catastrophic Forgetting},
author = {Hayes, Tyler L and Kafle, Kushal and Shrestha, Robik and Acharya, Manoj and Kanan, Christopher},
journal = {arXiv},
eprint = {1910.02509},
keywords = {},
}
@article{2017.Torralba.Zhou,
year = {2017},
title = {Places: A 10 Million Image Database for Scene Recognition},
author = {Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
doi = {10.1109/tpami.2017.2723009},
pmid = {28692961},
pages = {1452--1464},
number = {6},
volume = {40},
}
@article{1963.Hubel.Wiesel,
year = {1963},
title = {SINGLE-CELL RESPONSES IN STRIATE CORTEX OF KITTENS DEPRIVED OF VISION IN ONE EYE},
author = {Wiesel, Torsten N and Hubel, David H},
journal = {Journal of Neurophysiology},
issn = {0022-3077},
doi = {10.1152/jn.1963.26.6.1003},
pmid = {14084161},
pages = {1003--1017},
number = {6},
volume = {26},
keywords = {},
}
@article{2013.Elgammal.Elhoseiny,
year = {2013},
title = {Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions},
author = {Elhoseiny, Mohamed and Saleh, Babak and Elgammal, Ahmed},
journal = {2013 IEEE International Conference on Computer Vision},
doi = {10.1109/iccv.2013.321},
pages = {2584--2591},
}
@article{2008.Bandettini.Kriegeskorte,
year = {2008},
month = {12},
title = {Matching Categorical Object Representations in Inferior Temporal Cortex of Man and Monkey},
author = {Kriegeskorte, Nikolaus and Mur, Marieke and Ruff, Douglas A. and Kiani, Roozbeh and Bodurka, Jerzy and Esteky, Hossein and Tanaka, Keiji and Bandettini, Peter A.},
journal = {Neuron},
issn = {0896-6273},
doi = {10.1016/j.neuron.2008.10.043},
pmid = {19109916},
pages = {1126--1141},
number = {6},
volume = {60},
keywords = {},
}
@article{2005.Singer.Tsochantaridis,
year = {2005},
title = {Large margin methods for structured and interdependent output variables.},
author = {Tsochantaridis, Ioannis and Joachims, Thorsten and Hofmann, Thomas and Altun, Yasemin and Singer, Yoram},
journal = {Journal of machine learning research},
number = {9},
volume = {6},
}
@article{2021.Joulin.Caron,
year = {2021},
title = {Emerging Properties in Self-Supervised Vision Transformers},
author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jegou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
doi = {10.1109/iccv48922.2021.00951},
pages = {9630--9640},
volume = {00},
keywords = {},
}
@article{2021.Soricut.Changpinyo,
year = {2021},
title = {Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},
author = {Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00356},
pages = {3557--3567},
volume = {00},
keywords = {}
}
@article{2021.Zhan.Ye,
year = {2021},
title = {Learning Adaptive Classifiers Synthesis for Generalized Few-Shot Learning},
author = {Ye, Han-Jia and Hu, Hexiang and Zhan, De-Chuan},
journal = {International Journal of Computer Vision},
issn = {0920-5691},
doi = {10.1007/s11263-020-01381-4},
pages = {1930--1953},
number = {6},
volume = {129},
keywords = {},
}
@incollection{2000.Behrmann.Behrmann,
year = {2000},
rating = {0},
title = {Spatial Reference Frames and Hemispatial Neglect},
author = {Behrmann, M},
urldate = {0},
series = {The new cognitive neurosciences},
publisher = {The new cognitive neurosciences},
keywords = {},
}
@article{2019.Kalantidis.Kang,
year = {2019},
title = {Decoupling Representation and Classifier for Long-Tailed Recognition},
author = {Kang, Bingyi and Xie, Saining and Rohrbach, Marcus and Yan, Zhicheng and Gordo, Albert and Feng, Jiashi and Kalantidis, Yannis},
journal = {arXiv},
eprint = {1910.09217},
keywords = {},
}
@article{1984.Hubel.Livingstone,
year = {1984},
title = {Anatomy and physiology of a color system in the primate visual cortex},
author = {Livingstone, MS and Hubel, DH},
journal = {The Journal of Neuroscience},
issn = {0270-6474},
doi = {10.1523/jneurosci.04-01-00309.1984},
pmid = {6198495},
pages = {309--356},
number = {1},
volume = {4},
keywords = {},
}
@article{2019.Belongie.Cui,
year = {2019},
title = {Class-Balanced Loss Based on Effective Number of Samples},
author = {Cui, Yin and Jia, Menglin and Lin, Tsung-Yi and Song, Yang and Belongie, Serge},
journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr.2019.00949},
pages = {9260--9269},
volume = {00},
}
@article{2017.Sompolinsky.Chung,
year = {2017},
rating = {0},
title = {Classification and Geometry of General Perceptual Manifolds},
author = {Chung, SueYeon and Lee, Daniel D and Sompolinsky, Haim},
journal = {arXiv},
doi = {10.1103/physrevx.8.031003},
eprint = {1710.06487},
pages = {031003},
number = {3},
volume = {8},
keywords = {},
}
@article{2013.Kriegeskorte.Mur,
year = {2013},
title = {Human Object-Similarity Judgments Reflect and Transcend the Primate-IT Object Representation},
author = {Mur, Marieke and Meys, Mirjam and Bodurka, Jerzy and Goebel, Rainer and Bandettini, Peter A. and Kriegeskorte, Nikolaus},
journal = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2013.00128},
pmid = {23525516},
pmcid = {PMC3605517},
pages = {128},
volume = {4},
keywords = {},
}
@article{2018.Kumaran.Banino,
year = {2018},
rating = {0},
title = {Vector-based navigation using grid-like representations in artificial agents},
author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
journal = {Nature},
issn = {0028-0836},
doi = {10.1038/s41586-018-0102-6},
pmid = {29743670},
pages = {429--433},
number = {7705},
volume = {557},
language = {English},
keywords = {},
month = {05},
}
@article{2017.Livingstone.Arcarol,
year = {2017},
title = {A hierarchical, retinotopic proto-organization of the primate visual system at birth.},
author = {Arcaro, Michael J and Livingstone, Margaret S},
journal = {eLife},
doi = {10.7554/elife.26196},
pmid = {28671063},
pages = {e26196},
volume = {6},
keywords = {},
}
@article{2021.Hwang.Cai,
year = {2021},
title = {ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot},
author = {Cai, Jiarui and Wang, Yizhou and Hwang, Jenq-Neng},
journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
doi = {10.1109/iccv48922.2021.00018},
pages = {112--121},
volume = {00},
}
@article{2020.Krishnaswamy.Trenholm,
year = {2020},
title = {An Annotated Journey through Modern Visual Neuroscience},
author = {Trenholm, Stuart and Krishnaswamy, Arjun},
journal = {The Journal of Neuroscience},
issn = {0270-6474},
doi = {10.1523/jneurosci.1061-19.2019},
pmid = {31896562},
pages = {44--53},
number = {1},
volume = {40},
keywords = {},
}
@article{1994.Pearlmutter.Pearlmutter,
year = {1994},
rating = {0},
title = {Fast Exact Multiplication by the Hessian},
author = {Pearlmutter, Barak A},
journal = {Neural Computation},
issn = {0899-7667},
doi = {10.1162/neco.1994.6.1.147},
url = {http://www.bcl.hamilton.ie/\textbackslashtextasciitildebarak/papers/nc-hessian.pdf},
pages = {147--160},
number = {1},
volume = {6},
language = {English},
keywords = {},
}
@article{2019.Wermter.Parisi,
year = {2019},
title = {Continual lifelong learning with neural networks: A review},
author = {Parisi, German I. and Kemker, Ronald and Part, Jose L. and Kanan, Christopher and Wermter, Stefan},
journal = {Neural Networks},
issn = {0893-6080},
doi = {10.1016/j.neunet.2019.01.012},
pmid = {30780045},
pages = {54--71},
volume = {113},
keywords = {},
}
@article{2016.Poczos.Du,
year = {2016},
title = {Hypothesis Transfer Learning via Transformation Functions},
author = {Du, Simon Shaolei and Koushik, Jayanth and Singh, Aarti and Poczos, Barnabas},
journal = {arXiv},
doi = {10.48550/arxiv.1612.01020},
eprint = {1612.01020},
abstract = {We consider the Hypothesis Transfer Learning (HTL) problem where one incorporates a hypothesis trained on the source domain into the learning procedure of the target domain. Existing theoretical analysis either only studies specific algorithms or only presents upper bounds on the generalization error but not on the excess risk. In this paper, we propose a unified algorithm-dependent framework for HTL through a novel notion of transformation function, which characterizes the relation between the source and the target domains. We conduct a general risk analysis of this framework and in particular, we show for the first time, if two domains are related, HTL enjoys faster convergence rates of excess risks for Kernel Smoothing and Kernel Ridge Regression than those of the classical non-transfer learning settings. Experiments on real world data demonstrate the effectiveness of our framework.}
}
@article{2020.Ni.Wang,
year = {2020},
title = {Generalizing from a Few Examples},
author = {Wang, Yaqing and Yao, Quanming and Kwok, James T. and Ni, Lionel M.},
journal = {ACM Computing Surveys (CSUR)},
issn = {0360-0300},
doi = {10.1145/3386252},
pages = {1--34},
number = {3},
volume = {53},
keywords = {},
}
@article{2008.Kornprobst.Wohrer,
year = {2009},
rating = {0},
title = {Virtual Retina: A biological retina model and simulator, with contrast gain control},
author = {Wohrer, Adrien and Kornprobst, Pierre},
journal = {Journal of Computational Neuroscience},
issn = {0929-5313},
doi = {10.1007/s10827-008-0108-4},
pmid = {18670870},
pages = {219--249},
number = {2},
volume = {26},
language = {English},
keywords = {},
}
@article{2021.Girshick.He,
year = {2021},
title = {Masked Autoencoders Are Scalable Vision Learners},
author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
journal = {arXiv},
eprint = {2111.06377},
keywords = {},
}
@article{1967.Pettigrew.Barlow,
year = {1967},
title = {The neural mechanism of binocular depth discrimination},
author = {Barlow, H B and Blakemore, C and Pettigrew, J D},
journal = {The Journal of Physiology},
issn = {0022-3751},
doi = {10.1113/jphysiol.1967.sp008360},
pmid = {6065881},
pages = {327--342},
number = {2},
volume = {193},
keywords = {},
}
@article{2016.Cooper.Cooper,
year = {2016-04},
rating = {0},
title = {A normalized contrast-encoding model exhibits bright/dark asymmetries similar to early visual neurons},
author = {Cooper, Emily A},
journal = {Physiological Reports},
issn = {2051-817X},
doi = {10.14814/phy2.12746},
pmid = {27044852},
pmcid = {PMC4831320},
pages = {e12746},
number = {7},
volume = {4},
language = {English},
keywords = {},
}
@article{2013.Ng.Socher,
year = {2013},
title = {Zero-Shot Learning Through Cross-Modal Transfer},
author = {Socher, Richard and Ganjoo, Milind and Sridhar, Hamsa and Bastani, Osbert and Manning, Christopher D and Ng, Andrew Y},
journal = {arXiv},
doi = {10.48550/arxiv.1301.3666},
eprint = {1301.3666},
abstract = {This work introduces a model that can recognize objects in images even if no training data is available for the objects. The only necessary knowledge about the unseen categories comes from unsupervised large text corpora. In our zero-shot framework distributional information in language can be seen as spanning a semantic basis for understanding what objects look like. Most previous zero-shot learning models can only differentiate between unseen classes. In contrast, our model can both obtain state of the art performance on classes that have thousands of training images and obtain reasonable performance on unseen classes. This is achieved by first using outlier detection in the semantic space and then two separate recognition models. Furthermore, our model does not require any manually defined semantic features for either words or images.}
}
@article{2021.Vasconcelos.Cheng,
year = {2021},
title = {Learning Deep Classifiers Consistent with Fine-Grained Novelty Detection},
author = {Cheng, Jiacheng and Vasconcelos, Nuno},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00171},
pages = {1664--1673},
volume = {00},
keywords = {}
}
@article{2009.Maunsell.Cohen,
year = {2009},
title = {Attention improves performance primarily by reducing interneuronal correlations},
author = {Cohen, Marlene R and Maunsell, John H R},
journal = {Nature Neuroscience},
issn = {1097-6256},
doi = {10.1038/nn.2439},
pmid = {19915566},
pmcid = {PMC2820564},
pages = {1594--1600},
number = {12},
volume = {12},
keywords = {},
}
@article{2012.Poggio.Isik,
year = {2012},
rating = {0},
title = {Learning and disrupting invariance in visual recognition with a temporal association rule},
author = {Isik, Leyla and Leibo, Joel Z and Poggio, Tomaso},
journal = {Frontiers in Computational Neuroscience},
doi = {10.3389/fncom.2012.00037},
volume = {6},
language = {English},
keywords = {},
}
@article{2021.Chang.Hong,
year = {2021},
title = {Disentangling Label Distribution for Long-tailed Visual Recognition},
author = {Hong, Youngkyu and Han, Seungju and Choi, Kwanghee and Seo, Seokjun and Kim, Beomsu and Chang, Buru},
journal = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/cvpr46437.2021.00656},
pages = {6622--6632},
volume = {00},
keywords = {}
}
@article{2016.Ommer.Bautistao3y,
year = {2016},
title = {CliqueCNN: Deep Unsupervised Exemplar Learning},
author = {Bautista, Miguel A and Sanakoyeu, Artsiom and Sutter, Ekaterina and Ommer, Björn},
journal = {arXiv},
eprint = {1608.08792},
keywords = {}
}
@article{2014.Ramanan.Zhu,
year = {2014},
title = {Capturing Long-Tail Distributions of Object Subcategories},
author = {Zhu, Xiangxin and Anguelov, Dragomir and Ramanan, Deva},
journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr.2014.122},
pages = {915--922},
}
@article{2017.Araujo.Duque-Belfort,
year = {2017},
title = {Online Incremental Supervised Growing Neural Gas},
author = {Duque-Belfort, Felipe and Bassani, Hansenclever F. and Araujo, Aluizio F. R.},
journal = {2017 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/ijcnn.2017.7965966},
pages = {1034--1040},
keywords = {},
}
@article{2012.Sahinidis.Rios,
year = {2012},
rating = {0},
title = {Derivative-free optimization: a review of algorithms and comparison of software implementations},
author = {Rios, Luis Miguel and Sahinidis, Nikolaos V},
journal = {Journal of Global Optimization},
issn = {0925-5001},
doi = {10.1007/s10898-012-9951-y},
pages = {1247--1293},
number = {3},
volume = {56},
language = {English},
keywords = {},
month = {07},
}
@article{1992.Schmidhuber.Schmidhuber,
year = {1992},
title = {Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks},
author = {Schmidhuber, Jrgen},
journal = {Neural Computation},
issn = {0899-7667},
doi = {10.1162/neco.1992.4.1.131},
pages = {131--139},
number = {1},
volume = {4},
keywords = {},
}
@article{2012.Bressloff.Galtier,
year = {2012},
title = {Hebbian learning of recurrent connections: a geometrical perspective.},
author = {Galtier, Mathieu N and Faugeras, Olivier D and Bressloff, Paul C},
journal = {Neural computation},
issn = {0899-7667},
doi = {10.1162/neco\_a\_00322},
pmid = {22594830},
pages = {2346--83},
number = {9},
volume = {24},
keywords = {}
}
@article{2015.Salakhutdinov.Ba,
year = {2015},
title = {Predicting Deep Zero-Shot Convolutional Neural Networks Using Textual Descriptions},
author = {Ba, Jimmy Lei and Swersky, Kevin and Fidler, Sanja and Salakhutdinov, Ruslan},
journal = {2015 IEEE International Conference on Computer Vision (ICCV)},
doi = {10.1109/iccv.2015.483},
pages = {4247--4255},
}
@article{2017.Gerven.Gerven,
year = {2017},
rating = {0},
title = {Computational Foundations of Natural Intelligence},
author = {Gerven, Marcel van},
journal = {bioRxiv},
doi = {10.1101/166785},
pages = {166785},
language = {English},
keywords = {},
month = {07},
}
@article{2012.Seeger.Srinivas,
year = {2009},
rating = {0},
title = {Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting},
author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias W.},
journal = {IEEE Transactions on Information Theory},
issn = {0018-9448},
doi = {10.1109/tit.2011.2182033},
eprint = {0912.3995},
url = {arXiv.org},
pages = {3250--3265},
number = {5},
volume = {58},
keywords = {},
month = {12},
}
